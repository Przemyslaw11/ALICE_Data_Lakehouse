services:
  postgres:
    image: postgres:13
    platform: linux/amd64
    hostname: postgres
    container_name: postgres
    restart: always
    volumes:
      - ./data/pgdata:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=metastore
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d metastore"]
      interval: 5s
      retries: 10
    ports:
      - "5432:5432"
    networks:
      - dldg

  metastore:
    image: apache/hive:3.1.3
    hostname: metastore
    container_name: metastore
    restart: always
    platform: linux/amd64
    user: root
    volumes:
      - ./jars/postgresql-42.2.18.jar:/opt/hive/lib/postgresql-42.2.18.jar
      - ./jars/hadoop-aws-3.2.0.jar:/opt/hive/lib/hadoop-aws-3.2.0.jar
      - ./jars/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar
      - ./conf/hive-site.xml:/opt/hive/conf/hive-site.xml
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - METASTORE_DB_HOSTNAME=postgres
      - METASTORE_DB_PORT=5432
      - METASTORE_DB_NAME=metastore
      - METASTORE_DB_USER=postgres
      - METASTORE_DB_PASSWORD=postgres
    ports:
      - "9083:9083"
    command: >
      bash -c '
      apt-get update &&
      apt-get install -y netcat &&
      rm -rf /var/lib/apt/lists/* &&
      rm -f /opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-*.jar &&
      chown -R hive:hive /opt/hive &&
      cd /opt/hive/bin &&
      until nc -z postgres 5432; do
        echo "Waiting for PostgreSQL to start..."
        sleep 2
      done &&
      ./schematool -dbType postgres -validate || ./schematool -dbType postgres -initSchema --verbose &&
      su hive -c "/opt/hive/bin/hive --service metastore"
      '
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - dldg

  trinodb:
    restart: always
    image: trinodb/trino:426
    platform: linux/amd64
    hostname: trinodb
    container_name: trinodb
    volumes:
      - ./etc/catalog/delta.properties:/etc/trino/catalog/delta.properties
      - ./conf:/etc/hadoop/conf/
    ports:
      - "9090:8080"
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_KEY}
      - AWS_ENDPOINT=https://s3p.cloud.cyfronet.pl
      - AWS_DEFAULT_REGION=us-west-2
      - TRINO_ENDPOINT=http://trinodb:8080
    depends_on:
      - metastore
    networks:
      - dldg

  spark:
    image: bitnami/spark:3.4.1
    platform: linux/amd64
    hostname: spark
    container_name: spark
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./conf:/opt/spark/conf
      - ./jars:/opt/spark/jars
    networks:
      - dldg
    depends_on:
      - metastore

  spark-worker:
    image: bitnami/spark:3.4.1
    platform: linux/amd64
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_HOST=spark
      - SPARK_MASTER_PORT=7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    volumes:
      - ./conf:/opt/spark/conf
      - ./jars:/opt/spark/jars
    networks:
      - dldg
    depends_on:
      - spark

networks:
  dldg:
    name: dldg